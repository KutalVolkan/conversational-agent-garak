# Garak GPT-4o Assistant

This is a **Streamlit application** that provides a chat interface to a GPT-4o assistant enhanced with **Garak** (LLM vulnerability scanner) tool functions. The assistant can list and describe Garak probes, run vulnerability scans on a configured model, and summarize the results. It uses OpenAI's **function calling** to let GPT-4o autonomously use Garak's CLI under the hood.

---

## âœ¨ Features

- ğŸ’¬ **Conversational Interface** â€“ Chat with GPT-4o in a web UI.
- ğŸ§ª **Garak Integration** â€“ GPT-4o can call Garakâ€™s CLI to:
  - list available probes
  - describe specific probes
  - run a scan
  - summarize the scan
- ğŸ’¾ **Persistent History** â€“ Conversation state is stored between sessions.
- ğŸ§¼ **Clearable Session** â€“ Reset chat + scan logs from the sidebar.
- ğŸ§  **Context-aware** â€“ GPT-4o uses memory to continue discussions across steps.

---

## ğŸš€ Getting Started

### âœ… Prerequisites

- Python 3.9+
- OpenAI API key with access to GPT-4o
- Garak installed (`pip install garak`)
- A Garak REST config file (e.g. `rest_config.json`) that points to your model (e.g. OpenAI GPT-4o or local API)

---

### âš™ï¸ Installation

#### 1. Clone the repository

```bash
git clone https://github.com/yourusername/streamlit-garak-app.git
cd streamlit-garak-app
```

#### 2. Create and activate a virtual environment

**macOS / Linux**
```bash
python3 -m venv .venv
source .venv/bin/activate
```

**Windows (Command Prompt)**
```cmd
python -m venv .venv
.venv\Scripts\activate
```

**Windows (PowerShell)**
```powershell
python -m venv .venv
.\.venv\Scripts\Activate.ps1
```

#### 3. Install dependencies

```bash
pip install -r requirements.txt
```

> If you donâ€™t have `garak` already installed, you can also do:
> ```bash
> pip install garak
> ```

#### 4. Configure your API key

Create a `.env` file in the project root and add your OpenAI key:

```env
OPENAI_API_KEY=sk-...
```

Or set it in your terminal session before running the app.

---

### â–¶ï¸ Run the app

```bash
streamlit run app.py
```

Then open your browser to: [http://localhost:8501](http://localhost:8501)

---

## ğŸ§  Example Use Cases

You can simply type in the chat:

- `What probes are available?`
- `Describe the lmrc.Profanity probe.`
- `Run a scan using promptinject and goodside probes.`
- `Summarize the last scan.`

The assistant will respond, decide when to run tools, and maintain context.

---

## ğŸ“ Project Structure

```
streamlit_garak_app/
â”œâ”€â”€ app.py              # Streamlit UI + chat interface
â”œâ”€â”€ agent.py            # GPT-4o assistant logic (function calling, memory)
â”œâ”€â”€ garak_tools.py      # CLI integration for Garak tool functions
â”œâ”€â”€ rest_config.json    # Example config (for scanning GPT-4o via REST)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env                # Your OpenAI API key (not committed)
â””â”€â”€ README.md
```

---

## ğŸ§¹ Resetting the Session

Use the **"Clear History"** button in the sidebar to reset chat, scan logs, and memory.

---

## ğŸ” Security

Only defined tools are callable by GPT-4o via function calling. All subprocess access to Garak is controlled. Conversation data is stored locally for persistence only.

---

## ğŸ“œ License

MIT

---

## ğŸ™Œ Acknowledgments

- [NVIDIA Garak](https://github.com/NVIDIA/garak) â€“ LLM red teaming & robustness scanner
- [OpenAI](https://platform.openai.com/docs/guides/gpt) â€“ GPT-4o assistant
- [Streamlit](https://streamlit.io) â€“ The easiest way to build Python apps
